# ğŸƒâ€â™‚ï¸ Sistema de Reconocimiento de Actividades Humanas

Sistema de IA para detectar actividades humanas en tiempo real usando MediaPipe y Machine Learning.

## ğŸ¯ CaracterÃ­sticas

- **11 actividades detectadas**: Caminar, girar, sentarse, ponerse de pie, sentadillas, inclinaciones, etc.
- **98.2% de precisiÃ³n** en datos reales
- **Interfaz web moderna** con cÃ¡mara en tiempo real y anÃ¡lisis de videos
- **Modelo entrenado** con 17,124 muestras reales

## ğŸš€ InstalaciÃ³n y Uso

### Para Windows:
```cmd
# 1. Instalar dependencias (solo la primera vez)
install_windows.bat

# 2. Ejecutar la aplicaciÃ³n
run_windows.bat
```

**ğŸŒ La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en:** http://localhost:5000

### Para Linux/macOS:
```bash
# 1. Dar permisos de ejecuciÃ³n (solo la primera vez)
chmod +x install_unix.sh run_unix.sh

# 2. Instalar dependencias (solo la primera vez)
./install_unix.sh

# 3. Ejecutar la aplicaciÃ³n
./run_unix.sh
```

### Requisitos Previos:
- **Python 3.8+** instalado en tu sistema
- **CÃ¡mara web** conectada (para funciÃ³n en tiempo real)
- **ConexiÃ³n a internet** (para descargar dependencias)

**ğŸŒ La aplicaciÃ³n estarÃ¡ disponible en:** http://localhost:5000

## ğŸ“ Estructura del Proyecto

```
App_ProyectoFinal/
â”œâ”€â”€ app.py                        # ğŸš€ AplicaciÃ³n principal
â”œâ”€â”€ create_real_model.py          # ğŸ¤– Crear modelo desde datos
â”œâ”€â”€ eda_proyecto_final.py         # ğŸ“Š AnÃ¡lisis exploratorio
â”œâ”€â”€ models/                       # ğŸ§  Modelos entrenados
â”‚   â”œâ”€â”€ activity_model.pkl
â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â””â”€â”€ label_encoder.pkl
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ pose_processor.py     # MediaPipe
â”‚   â”‚   â””â”€â”€ activity_predictor.py # PredicciÃ³n
â”‚   â”œâ”€â”€ interface/
â”‚   â”‚   â””â”€â”€ gradio_app.py         # Interfaz Web
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ feature_extractor_real.py # ExtracciÃ³n caracterÃ­sticas
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ all_video_landmarks_mediapipe.json  # Datos landmarks
â”‚   â””â”€â”€ VIDEOS FINAL TALLER LABELING.json  # Etiquetas
â””â”€â”€ venv/                         # Entorno virtual
```

## ğŸ­ Actividades Detectadas

1. **Caminar acercÃ¡ndose**
2. **Caminar alejÃ¡ndose (espaldas)**
3. **Giro 180Â° derecha**
4. **Giro 180Â° izquierda**
5. **Inclinarse derecha**
6. **Inclinarse izquierda**
7. **Parado sin movimiento**
8. **Ponerse de pie**
9. **Sentadillas**
10. **Sentado sin movimiento**
11. **Sentarse**

## ğŸ› ï¸ TecnologÃ­as

- **MediaPipe**: DetecciÃ³n de pose
- **scikit-learn**: Machine Learning  
- **Flask**: Interfaz web moderna
- **Python 3.12**

## ğŸ“Š Rendimiento del Modelo

- **PrecisiÃ³n**: 98.2%
- **Datos de entrenamiento**: 17,124 muestras
- **CaracterÃ­sticas**: 31 por frame
- **Algoritmo**: Random Forest

## ğŸ® Funcionalidades

### ğŸ“¹ CÃ¡mara en Tiempo Real
- **DetecciÃ³n instantÃ¡nea** de actividades
- **VisualizaciÃ³n de landmarks** de pose en tiempo real
- **Confianza actualizada** cada 500ms
- **Interfaz web moderna** y responsive

### ğŸ® CÃ³mo Usar la AplicaciÃ³n
1. Ejecuta `run_windows.bat`
2. Abre tu navegador en `http://localhost:5000`
3. Haz clic en "ğŸ“¹ Iniciar CÃ¡mara"
4. Â¡Realiza movimientos y observa la detecciÃ³n en tiempo real!

## ğŸ”§ Desarrollo

Para re-entrenar el modelo:
```bash
python create_real_model.py
```
